{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WMg6khcwMoLH",
        "outputId": "54ccd349-f30d-421b-ba46-d88ce475f415"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unsmoothed Sentence Probability: 0.07407407407407407\n",
            "Smoothed Sentence Probability: 1.0101357919757919e-05\n"
          ]
        }
      ],
      "source": [
        "from collections import Counter\n",
        "\n",
        "# Define the corpus and the target sentence\n",
        "corpus_sentences = [\n",
        "    \"<s> He read a book </s>\",\n",
        "    \"<s> I read a different book </s>\",\n",
        "    \"<s> He read a book by Danielle </s>\"\n",
        "]\n",
        "target_sentence = \"<s> I read a book by Danielle </s>\"\n",
        "\n",
        "# Tokenize the corpus into individual words\n",
        "tokens = [word for sentence in corpus_sentences for word in sentence.split()]\n",
        "\n",
        "# Generate bigrams from the corpus tokens\n",
        "bigrams = [(tokens[i], tokens[i + 1]) for i in range(len(tokens) - 1)]\n",
        "\n",
        "# Count the occurrences of each bigram and each word in the corpus\n",
        "bigram_counts = Counter(bigrams)\n",
        "word_counts = Counter(tokens)\n",
        "\n",
        "# Determine the vocabulary size for smoothing purposes\n",
        "vocabulary = set(tokens)\n",
        "V = len(vocabulary)  # Vocabulary size\n",
        "\n",
        "# Function to calculate unsmoothed bigram probability\n",
        "def calculate_unsmoothed_probability(bigram):\n",
        "    return bigram_counts[bigram] / word_counts[bigram[0]] if word_counts[bigram[0]] > 0 else 0\n",
        "\n",
        "# Function to calculate smoothed (add-one) bigram probability\n",
        "def calculate_smoothed_probability(bigram, V):\n",
        "    return (bigram_counts.get(bigram, 0) + 1) / (word_counts.get(bigram[0], 0) + V)\n",
        "\n",
        "# Function to calculate the probability of a sentence using a specified bigram probability function\n",
        "def calculate_sentence_probability(sentence, probability_function, V=None):\n",
        "    tokens = sentence.split()\n",
        "    bigrams = [(tokens[i], tokens[i + 1]) for i in range(len(tokens) - 1)]\n",
        "    probability = 1.0\n",
        "    for bigram in bigrams:\n",
        "        # Check if the smoothing parameter V should be passed\n",
        "        if V is not None:\n",
        "            probability *= probability_function(bigram, V)\n",
        "        else:\n",
        "            probability *= probability_function(bigram)\n",
        "    return probability\n",
        "\n",
        "# Calculate and print the sentence probabilities using both unsmoothed and smoothed models\n",
        "unsmoothed_probability = calculate_sentence_probability(target_sentence, calculate_unsmoothed_probability)\n",
        "smoothed_probability = calculate_sentence_probability(target_sentence, calculate_smoothed_probability, V)\n",
        "\n",
        "print(\"Unsmoothed Sentence Probability:\", unsmoothed_probability)\n",
        "print(\"Smoothed Sentence Probability:\", smoothed_probability)\n"
      ]
    }
  ]
}